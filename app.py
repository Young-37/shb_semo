# app.py
import os
import streamlit as st
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import PyPDFLoader
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

st.set_page_config(page_title="ìƒí’ˆì„¤ëª… ë„ìš°ë¯¸", layout="wide")
st.title("ğŸ“‘ ìƒí’ˆì„¤ëª… ë„ìš°ë¯¸ (ì˜ì—…ì ìš©)")

# 1) OpenAI API í‚¤: (í™˜ê²½ë³€ìˆ˜ì— ì—†ìœ¼ë©´ ì…ë ¥ë°›ì•„ ì„¸ì…˜ì— ì„¤ì •)
env_key = os.environ.get("OPENAI_API_KEY")
if not env_key:
    st.info("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY ë˜ëŠ” ì•„ë˜ ì…ë ¥)")
    key_input = st.text_input("OpenAI API Key (sk-...)", type="password")
    if key_input:
        os.environ["OPENAI_API_KEY"] = key_input
else:
    st.write("ğŸ”’ OpenAI API Key detected in environment.")

# ëª¨ë¸ ì„ íƒ (gpt-4o ì ‘ê·¼ê¶Œí•œ ì—†ë‹¤ë©´ 'gpt-3.5-turbo'ë¡œ ë°”ê¿” ì‚¬ìš©)
model_name = st.selectbox("ëª¨ë¸ ì„ íƒ (í…ŒìŠ¤íŠ¸ìš©)", ["gpt-4o", "gpt-3.5-turbo"])

# PDF ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)
uploaded_files = st.file_uploader("ìƒí’ˆì„¤ëª…ì„œ PDF ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", accept_multiple_files=True, type=["pdf"])

if uploaded_files:
    st.info("PDFë¥¼ ë¡œì»¬ì— ì €ì¥í•˜ê³  ë¬¸ì„œë¥¼ ì¸ë±ì‹±í•©ë‹ˆë‹¤. ì¡°ê¸ˆ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆì–´ìš”.")
    os.makedirs("docs", exist_ok=True)
    all_docs = []

    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)

    for uploaded_file in uploaded_files:
        dest_path = os.path.join("docs", uploaded_file.name)
        # ì—…ë¡œë“œ íŒŒì¼ì„ ë¡œì»¬ì— ì €ì¥
        with open(dest_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        # PDF ë¡œë“œ ë° ë¶„ë¦¬
        loader = PyPDFLoader(dest_path)
        raw_docs = loader.load()
        docs = splitter.split_documents(raw_docs)

        # ë¬¸ë‹¨ë§ˆë‹¤ ì¶œì²˜(metadata) ì„¤ì • (íŒŒì¼ëª… + í˜ì´ì§€)
        for d in docs:
            page = d.metadata.get("page")  # PyPDFLoaderëŠ” ì¢…ì¢… 'page'ë¥¼ ë„£ì–´ì¤Œ
            filename = uploaded_file.name
            if page is not None:
                d.metadata["source"] = f"{filename} (p.{int(page)+1})"
            else:
                d.metadata["source"] = filename
        all_docs.extend(docs)

    # ì„ë² ë”© ë° ë²¡í„° DB (FAISS)
    embeddings = OpenAIEmbeddings()  # OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”
    vectorstore = FAISS.from_documents(all_docs, embeddings)

    # Retriever + LLM + RetrievalQA
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    llm = ChatOpenAI(model_name=model_name, temperature=0)
    qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)

    st.success("ì¸ë±ì‹± ì™„ë£Œ! ì§ˆì˜ ì…ë ¥í•˜ì„¸ìš”.")
    query = st.text_input("ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš” ğŸ‘‡")

    if query:
        with st.spinner("ê²€ìƒ‰Â·ì‘ë‹µ ìƒì„± ì¤‘..."):
            result = qa({"query": query})
            # langchain ë²„ì „ì— ë”°ë¼ ë°˜í™˜ í‚¤ê°€ ë‹¬ë¼ì„œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            answer = result.get("result") or result.get("answer") or result.get("output_text") or str(result)
            st.markdown("### ğŸ’¬ AI ë‹µë³€")
            st.write(answer)

            source_docs = result.get("source_documents") or []
            if source_docs:
                st.markdown("### ğŸ“– ì¶œì²˜ (ë¬¸ë‹¨ ì¼ë¶€ + íŒŒì¼ëª…/í˜ì´ì§€)")
                for i, doc in enumerate(source_docs, 1):
                    src = doc.metadata.get("source", "unknown")
                    snippet = doc.page_content.strip().replace("\n", " ")[:300]
                    st.write(f"{i}. ({src}) {snippet}...")
            else:
                st.write("ì¶œì²˜ ë¬¸ë‹¨ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

